{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The dataset collected is related to 17 campaigns that occurred between May 2008 and November 2010, corresponding to a total of 79354 contacts.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bank-additional-full.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 21)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "job               0\n",
       "marital           0\n",
       "education         0\n",
       "default           0\n",
       "housing           0\n",
       "loan              0\n",
       "contact           0\n",
       "month             0\n",
       "day_of_week       0\n",
       "duration          0\n",
       "campaign          0\n",
       "pdays             0\n",
       "previous          0\n",
       "poutcome          0\n",
       "emp.var.rate      0\n",
       "cons.price.idx    0\n",
       "cons.conf.idx     0\n",
       "euribor3m         0\n",
       "nr.employed       0\n",
       "y                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types and missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "There are no null values in the dataset, though there are \"unknown\" values, which could be considered missing.  Let's count how many unknowns there are.\n",
    "\n",
    "Note: as pointed out in the description, we should not include 'duration' in our predictive models as it is not known before a call is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'unknown' values in each column:\n",
      "job: 330\n",
      "marital: 80\n",
      "education: 1731\n",
      "default: 8597\n",
      "housing: 990\n",
      "loan: 990\n",
      "\n",
      "Percent of 'unknown' values in each column:\n",
      "job: 0.8%\n",
      "marital: 0.19%\n",
      "education: 4.2%\n",
      "default: 20.87%\n",
      "housing: 2.4%\n",
      "loan: 2.4%\n"
     ]
    }
   ],
   "source": [
    "# List of columns to check\n",
    "unknown_cols = [\"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\"]\n",
    "\n",
    "# Initialize a dictionary to store counts for each column\n",
    "unknown_counts = {}\n",
    "\n",
    "# Loop through each column\n",
    "for col in unknown_cols:\n",
    "  # Count the number of \"unknown\" values in the column\n",
    "  unknown_counts[col] = (df[col] == \"unknown\").sum()\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of 'unknown' values in each column:\")\n",
    "for col, count in unknown_counts.items():\n",
    "  print(f\"{col}: {count}\")\n",
    "\n",
    "print(\"\\nPercent of 'unknown' values in each column:\")\n",
    "for col, count in unknown_counts.items():\n",
    "  print(f\"{col}: {round(100*count/len(df), 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Objective\n",
    "\n",
    "To build a predictive model that can identify potential bank clients who are more likely to subscribe to a term deposit based on their characteristics and past interactions with the bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features, prepare the features and target column for modeling with appropriate encoding and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded bank features:\n",
      "         age  job_admin.  job_blue-collar  job_entrepreneur  job_housemaid  \\\n",
      "0  1.533034       False            False             False           True   \n",
      "1  1.628993       False            False             False          False   \n",
      "2 -0.290186       False            False             False          False   \n",
      "3 -0.002309        True            False             False          False   \n",
      "4  1.533034       False            False             False          False   \n",
      "\n",
      "   job_management  job_retired  job_self-employed  job_services  job_student  \\\n",
      "0           False        False              False         False        False   \n",
      "1           False        False              False          True        False   \n",
      "2           False        False              False          True        False   \n",
      "3           False        False              False         False        False   \n",
      "4           False        False              False          True        False   \n",
      "\n",
      "   ...  default_no  default_unknown  default_yes  housing_no  housing_unknown  \\\n",
      "0  ...        True            False        False        True            False   \n",
      "1  ...       False             True        False        True            False   \n",
      "2  ...        True            False        False       False            False   \n",
      "3  ...        True            False        False        True            False   \n",
      "4  ...        True            False        False        True            False   \n",
      "\n",
      "   housing_yes  loan_no  loan_unknown  loan_yes  y  \n",
      "0        False     True         False     False  0  \n",
      "1        False     True         False     False  0  \n",
      "2         True     True         False     False  0  \n",
      "3        False     True         False     False  0  \n",
      "4        False    False         False      True  0  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "\n",
      "Encoded target variable:\n",
      " 0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select bank information features and target variable\n",
    "bank_features = [\"age\", \"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\"]\n",
    "target_variable = \"y\"\n",
    "\n",
    "# Encode categorical features using one-hot encoding\n",
    "encoded_data = pd.get_dummies(df[bank_features])\n",
    "\n",
    "# Scale the age column\n",
    "scaler = StandardScaler()\n",
    "encoded_data[\"age\"] = scaler.fit_transform(encoded_data[[\"age\"]])\n",
    "\n",
    "# Encode target variable (y) as numerical\n",
    "target_encoded = {\"yes\": 1, \"no\": 0}\n",
    "reverse_target_encoded = {value: key for key, value in target_encoded.items()}\n",
    "encoded_data[target_variable] = df[target_variable].map(target_encoded)\n",
    "\n",
    "print(\"Encoded bank features:\\n\", encoded_data.head())\n",
    "print(\"\\nEncoded target variable:\\n\", encoded_data[\"y\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Train/Test Split\n",
    "\n",
    "With your data prepared, split it into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32950, 34) (8238, 34) (32950,) (8238,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = encoded_data.drop('y', axis=1)  # Features\n",
    "y = encoded_data['y']  # Target variable\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline performance: 88.76%\n",
      "Baseline test data performance: 88.65%\n",
      "Majority class: no\n"
     ]
    }
   ],
   "source": [
    "# Calculate class frequencies\n",
    "train_class_counts = y_train.value_counts()\n",
    "test_class_counts = y_test.value_counts()\n",
    "\n",
    "# Get the majority class in the training data\n",
    "majority_class = train_class_counts.idxmax()\n",
    "\n",
    "# Calculate baseline accuracy (percentage of instances in the majority class)\n",
    "baseline_train_accuracy = (train_class_counts[majority_class] / len(y_train)) * 100\n",
    "baseline_test_accuracy = (test_class_counts[majority_class] / len(y_test)) * 100\n",
    "\n",
    "# Print the results\n",
    "print(f\"Baseline performance: {baseline_train_accuracy:.2f}%\")\n",
    "print(f\"Baseline test data performance: {baseline_test_accuracy:.2f}%\")\n",
    "print(f\"Majority class: {reverse_target_encoded[majority_class]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: A Simple Model\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Score the Model\n",
    "\n",
    "What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8865015780529255\n",
      "Confusion Matrix:\n",
      " [[7303    0]\n",
      " [ 935    0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7303\n",
      "           1       0.00      0.00      0.00       935\n",
      "\n",
      "    accuracy                           0.89      8238\n",
      "   macro avg       0.44      0.50      0.47      8238\n",
      "weighted avg       0.79      0.89      0.83      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred, zero_division=0.0)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Model Comparisons\n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
    "\n",
    "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "| ----- | ---------- | -------------  | -----------   |\n",
    "|     |    |.     |.     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Time</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.076391</td>\n",
       "      <td>0.887557</td>\n",
       "      <td>0.886502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>0.889712</td>\n",
       "      <td>0.873877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.071658</td>\n",
       "      <td>0.916601</td>\n",
       "      <td>0.861131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>27.116919</td>\n",
       "      <td>0.888225</td>\n",
       "      <td>0.886744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train Time  Train Accuracy  Test Accuracy\n",
       "0  Logistic Regression    0.076391        0.887557       0.886502\n",
       "1                  KNN    0.004819        0.889712       0.873877\n",
       "2        Decision Tree    0.071658        0.916601       0.861131\n",
       "3                  SVM   27.116919        0.888225       0.886744"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "\n",
    "model_results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "  start_time = time()\n",
    "  model.fit(X_train, y_train)\n",
    "  end_time = time()\n",
    "  train_time = end_time - start_time\n",
    "  \n",
    "  y_train_pred = model.predict(X_train)\n",
    "  train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "  \n",
    "  y_test_pred = model.predict(X_test)\n",
    "  test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "  \n",
    "  model_results.append({'Model': model_name,\n",
    "                        'Train Time': train_time,\n",
    "                        'Train Accuracy': train_accuracy,\n",
    "                        'Test Accuracy': test_accuracy})\n",
    "\n",
    "model_results = pd.DataFrame(model_results)\n",
    "\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11: Improving the Model\n",
    "\n",
    "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
    "\n",
    "- More feature engineering and exploration.  For example, should we keep the gender feature?  Why or why not?\n",
    "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
    "- Adjust your performance metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More feature engineering and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Including additional features\n",
    "additional_features = [\n",
    "    'contact', 'month', 'day_of_week',\n",
    "    'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',\n",
    "    'euribor3m', 'nr.employed', 'pdays', 'was_contacted_before'\n",
    "]\n",
    "\n",
    "# Feature engineering: Add binary feature\n",
    "df['was_contacted_before'] = (df['pdays'] != 999).astype(int)\n",
    "\n",
    "# Replace 999 with NaN\n",
    "df['pdays'] = df['pdays'].replace(999, np.nan)\n",
    "\n",
    "# Updated list of features\n",
    "all_features = bank_features + additional_features\n",
    "\n",
    "# Extracting the updated features and target\n",
    "X_all = df[all_features]\n",
    "y_all = df[target_variable]\n",
    "\n",
    "# Encoding the target variable\n",
    "y_all = y_all.map({'yes': 1, 'no': 0})\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X_all, y_all, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Defining the preprocessing steps for the updated features\n",
    "numeric_features = ['pdays', 'age', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = ['was_contacted_before', 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combining the transformers into a single ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Applying the transformations\n",
    "X_train_all_transformed = preprocessor.fit_transform(X_train_all)\n",
    "X_test_all_transformed = preprocessor.transform(X_test_all)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN': KNeighborsClassifier(n_neighbors=11),\n",
       " 'Logistic Regression': LogisticRegression(C=0.01, max_iter=1000),\n",
       " 'Decision Tree': DecisionTreeClassifier(max_depth=10, min_samples_split=20),\n",
       " 'SVM': SVC(C=1)}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*A worker stopped while some jobs were given to the executor.*\")\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "def tune_model(clf, param_grid, X_train, y_train):\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Defining parameter grids for each model\n",
    "param_grids = {\n",
    "    'KNN': {'n_neighbors': [3, 5, 7, 9, 11]},\n",
    "    'Logistic Regression': {'C': [0.01, 0.1, 1, 10, 100]},\n",
    "    'Decision Tree': {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 10, 20]},\n",
    "    'SVM': {'C': [0.01, 0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "}\n",
    "\n",
    "# Initialize classifiers with default settings\n",
    "classifiers = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'SVM': SVC()\n",
    "}\n",
    "\n",
    "# Tune each model\n",
    "best_models = {}\n",
    "for name, clf in classifiers.items():\n",
    "    best_models[name] = tune_model(clf, param_grids[name], X_train_all_transformed, y_train_all)\n",
    "\n",
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Time</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>0.903472</td>\n",
       "      <td>0.891640</td>\n",
       "      <td>0.540850</td>\n",
       "      <td>0.238301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.034505</td>\n",
       "      <td>0.892442</td>\n",
       "      <td>0.891317</td>\n",
       "      <td>0.557214</td>\n",
       "      <td>0.161267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.104743</td>\n",
       "      <td>0.910582</td>\n",
       "      <td>0.895849</td>\n",
       "      <td>0.579688</td>\n",
       "      <td>0.267099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>33.094671</td>\n",
       "      <td>0.904478</td>\n",
       "      <td>0.896253</td>\n",
       "      <td>0.604697</td>\n",
       "      <td>0.222462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train Time  Train Accuracy  Test Accuracy  Precision  \\\n",
       "0                  KNN    0.007304        0.903472       0.891640   0.540850   \n",
       "1  Logistic Regression    0.034505        0.892442       0.891317   0.557214   \n",
       "2        Decision Tree    0.104743        0.910582       0.895849   0.579688   \n",
       "3                  SVM   33.094671        0.904478       0.896253   0.604697   \n",
       "\n",
       "     Recall  \n",
       "0  0.238301  \n",
       "1  0.161267  \n",
       "2  0.267099  \n",
       "3  0.222462  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Function to train, evaluate classifiers, and record train time\n",
    "def evaluate_classifiers_with_time(classifiers, X_train, y_train, X_test, y_test):\n",
    "    results = []\n",
    "    confusion_matrices = {}\n",
    "    classification_reports = {}\n",
    "    for name, clf in classifiers.items():\n",
    "        start_time = time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        # Training performance\n",
    "        y_train_pred = clf.predict(X_train)\n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "        \n",
    "        # Test performance\n",
    "        y_test_pred = clf.predict(X_test)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "        # Calculate precision and recall\n",
    "        precision = precision_score(y_test, y_test_pred, zero_division=0.0)\n",
    "        recall = recall_score(y_test, y_test_pred, zero_division=0.0)\n",
    "\n",
    "        confusion_matrices[name] = confusion_matrix(y_test, y_test_pred)\n",
    "        classification_reports[name] = classification_report(y_test, y_test_pred, zero_division=0.0)\n",
    "        \n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Train Time': train_time,\n",
    "            'Train Accuracy': train_accuracy,\n",
    "            'Test Accuracy': test_accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall\n",
    "        })\n",
    "    return pd.DataFrame(results), confusion_matrices, classification_reports\n",
    "\n",
    "# Evaluate the tuned models\n",
    "tuned_results, confusion_matrices, classification_reports = evaluate_classifiers_with_time(best_models, X_train_all_transformed, y_train_all, X_test_all_transformed, y_test_all)\n",
    "\n",
    "tuned_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrices for Each Model\n",
      "\n",
      "Model KNN\n",
      "[[10687   281]\n",
      " [ 1058   331]]\n",
      "\n",
      "\n",
      "Model Logistic Regression\n",
      "[[10790   178]\n",
      " [ 1165   224]]\n",
      "\n",
      "\n",
      "Model Decision Tree\n",
      "[[10702   266]\n",
      " [ 1017   372]]\n",
      "\n",
      "\n",
      "Model SVM\n",
      "[[10766   202]\n",
      " [ 1080   309]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrices for Each Model\\n\")\n",
    "for key in confusion_matrices:\n",
    "    print(f\"Model {key}\")\n",
    "    print(confusion_matrices[key])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94     10968\n",
      "           1       0.54      0.24      0.33      1389\n",
      "\n",
      "    accuracy                           0.89     12357\n",
      "   macro avg       0.73      0.61      0.64     12357\n",
      "weighted avg       0.87      0.89      0.87     12357\n",
      "\n",
      "\n",
      "\n",
      "Model Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94     10968\n",
      "           1       0.56      0.16      0.25      1389\n",
      "\n",
      "    accuracy                           0.89     12357\n",
      "   macro avg       0.73      0.57      0.60     12357\n",
      "weighted avg       0.86      0.89      0.86     12357\n",
      "\n",
      "\n",
      "\n",
      "Model Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94     10968\n",
      "           1       0.58      0.27      0.37      1389\n",
      "\n",
      "    accuracy                           0.90     12357\n",
      "   macro avg       0.75      0.62      0.66     12357\n",
      "weighted avg       0.88      0.90      0.88     12357\n",
      "\n",
      "\n",
      "\n",
      "Model SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94     10968\n",
      "           1       0.60      0.22      0.33      1389\n",
      "\n",
      "    accuracy                           0.90     12357\n",
      "   macro avg       0.76      0.60      0.63     12357\n",
      "weighted avg       0.87      0.90      0.87     12357\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in classification_reports:\n",
    "    print(f\"Model {key}\")\n",
    "    print(classification_reports[key])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Feature Importance:\n",
      "                          Feature  Importance (abs)  Importance\n",
      "49                      month_may          0.566202   -0.566202\n",
      "2                    emp.var.rate          0.460066   -0.460066\n",
      "48                      month_mar          0.450091    0.450091\n",
      "6                     nr.employed          0.436332   -0.436332\n",
      "3                  cons.price.idx          0.316086    0.316086\n",
      "42              contact_telephone          0.265503   -0.265503\n",
      "41               contact_cellular          0.262162    0.262162\n",
      "50                      month_nov          0.173952   -0.173952\n",
      "54                day_of_week_mon          0.171118   -0.171118\n",
      "46                      month_jul          0.170307    0.170307\n",
      "5                       euribor3m          0.157825   -0.157825\n",
      "4                   cons.conf.idx          0.139744    0.139744\n",
      "16                    job_student          0.133404    0.133404\n",
      "13                    job_retired          0.122104    0.122104\n",
      "33                default_unknown          0.107730   -0.107730\n",
      "32                     default_no          0.105636    0.105636\n",
      "9                 job_blue-collar          0.103785   -0.103785\n",
      "57                day_of_week_wed          0.099516    0.099516\n",
      "52                      month_sep          0.097612   -0.097612\n",
      "30    education_university.degree          0.088505    0.088505\n",
      "47                      month_jun          0.085668    0.085668\n",
      "55                day_of_week_thu          0.076752    0.076752\n",
      "26             education_basic.9y          0.073838   -0.073838\n",
      "15                   job_services          0.069755   -0.069755\n",
      "45                      month_dec          0.058708    0.058708\n",
      "14              job_self-employed          0.055845   -0.055845\n",
      "11                  job_housemaid          0.052007   -0.052007\n",
      "8                      job_admin.          0.047841    0.047841\n",
      "53                day_of_week_fri          0.047412   -0.047412\n",
      "44                      month_aug          0.039768    0.039768\n",
      "56                day_of_week_tue          0.038921    0.038921\n",
      "27          education_high.school          0.037661   -0.037661\n",
      "17                 job_technician          0.037572    0.037572\n",
      "19                    job_unknown          0.037326   -0.037326\n",
      "20               marital_divorced          0.037244   -0.037244\n",
      "18                 job_unemployed          0.037028    0.037028\n",
      "10               job_entrepreneur          0.035400   -0.035400\n",
      "51                      month_oct          0.032357    0.032357\n",
      "22                 marital_single          0.031258    0.031258\n",
      "35                     housing_no          0.029782    0.029782\n",
      "0                           pdays          0.028786   -0.028786\n",
      "12                 job_management          0.027172   -0.027172\n",
      "40                       loan_yes          0.025695    0.025695\n",
      "25             education_basic.6y          0.021466    0.021466\n",
      "37                    housing_yes          0.019656   -0.019656\n",
      "28           education_illiterate          0.016298    0.016298\n",
      "38                        loan_no          0.015569   -0.015569\n",
      "36                housing_unknown          0.013467   -0.013467\n",
      "39                   loan_unknown          0.013467   -0.013467\n",
      "23                marital_unknown          0.010970    0.010970\n",
      "24             education_basic.4y          0.008341   -0.008341\n",
      "21                marital_married          0.008326   -0.008326\n",
      "29  education_professional.course          0.005464   -0.005464\n",
      "31              education_unknown          0.004305   -0.004305\n",
      "7          was_contacted_before_1          0.003341   -0.003341\n",
      "43                      month_apr          0.002474   -0.002474\n",
      "1                             age          0.002236    0.002236\n",
      "34                    default_yes          0.001247   -0.001247\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming Logistic Regression is in best_models['Logistic Regression']\n",
    "logistic_model = best_models['Logistic Regression']\n",
    "\n",
    "# Get the feature names after transformation\n",
    "feature_names = numeric_features + list(preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features))\n",
    "\n",
    "# Get the absolute value of coefficients to assess feature importance\n",
    "logistic_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance (abs)': np.abs(logistic_model.coef_[0]),\n",
    "    'Importance': logistic_model.coef_[0]\n",
    "}).sort_values(by='Importance (abs)', ascending=False)\n",
    "\n",
    "print(\"Logistic Regression Feature Importance:\")\n",
    "print(logistic_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Feature Importance:\n",
      "                          Feature  Importance\n",
      "6                     nr.employed    0.524380\n",
      "0                           pdays    0.107866\n",
      "5                       euribor3m    0.084214\n",
      "4                   cons.conf.idx    0.057416\n",
      "1                             age    0.056091\n",
      "51                      month_oct    0.021374\n",
      "41               contact_cellular    0.017387\n",
      "54                day_of_week_mon    0.012622\n",
      "43                      month_apr    0.008988\n",
      "3                  cons.price.idx    0.008103\n",
      "30    education_university.degree    0.006434\n",
      "22                 marital_single    0.005806\n",
      "38                        loan_no    0.005263\n",
      "57                day_of_week_wed    0.005040\n",
      "53                day_of_week_fri    0.005023\n",
      "20               marital_divorced    0.004834\n",
      "16                    job_student    0.004806\n",
      "31              education_unknown    0.004799\n",
      "9                 job_blue-collar    0.004644\n",
      "29  education_professional.course    0.004616\n",
      "17                 job_technician    0.004176\n",
      "8                      job_admin.    0.003841\n",
      "25             education_basic.6y    0.003585\n",
      "26             education_basic.9y    0.003481\n",
      "33                default_unknown    0.003184\n",
      "32                     default_no    0.002532\n",
      "46                      month_jul    0.002490\n",
      "27          education_high.school    0.002446\n",
      "13                    job_retired    0.002227\n",
      "42              contact_telephone    0.002210\n",
      "18                 job_unemployed    0.002021\n",
      "14              job_self-employed    0.001747\n",
      "35                     housing_no    0.001728\n",
      "11                  job_housemaid    0.001648\n",
      "12                 job_management    0.001492\n",
      "37                    housing_yes    0.001367\n",
      "47                      month_jun    0.001329\n",
      "50                      month_nov    0.001231\n",
      "56                day_of_week_tue    0.001229\n",
      "48                      month_mar    0.001074\n",
      "49                      month_may    0.000826\n",
      "10               job_entrepreneur    0.000774\n",
      "55                day_of_week_thu    0.000762\n",
      "23                marital_unknown    0.000736\n",
      "24             education_basic.4y    0.000677\n",
      "15                   job_services    0.000551\n",
      "28           education_illiterate    0.000453\n",
      "36                housing_unknown    0.000275\n",
      "40                       loan_yes    0.000200\n",
      "21                marital_married    0.000000\n",
      "44                      month_aug    0.000000\n",
      "7          was_contacted_before_1    0.000000\n",
      "52                      month_sep    0.000000\n",
      "19                    job_unknown    0.000000\n",
      "2                    emp.var.rate    0.000000\n",
      "39                   loan_unknown    0.000000\n",
      "34                    default_yes    0.000000\n",
      "45                      month_dec    0.000000\n"
     ]
    }
   ],
   "source": [
    "# Assuming Decision Tree is in best_models['Decision Tree']\n",
    "tree_model = best_models['Decision Tree']\n",
    "\n",
    "# Get the feature importances\n",
    "tree_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': tree_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Decision Tree Feature Importance:\")\n",
    "print(tree_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation Importance for SVM:\n",
      "                          Feature    Importance\n",
      "2                    emp.var.rate  4.009064e-02\n",
      "3                  cons.price.idx  1.842680e-02\n",
      "0                           pdays  4.863640e-03\n",
      "6                     nr.employed  3.916808e-03\n",
      "51                      month_oct  1.108683e-03\n",
      "4                   cons.conf.idx  1.043943e-03\n",
      "54                day_of_week_mon  7.849802e-04\n",
      "42              contact_telephone  3.884438e-04\n",
      "41               contact_cellular  3.884438e-04\n",
      "20               marital_divorced  3.722586e-04\n",
      "57                day_of_week_wed  2.832403e-04\n",
      "27          education_high.school  2.751477e-04\n",
      "12                 job_management  2.508700e-04\n",
      "22                 marital_single  2.104071e-04\n",
      "44                      month_aug  2.104071e-04\n",
      "48                      month_mar  1.861293e-04\n",
      "24             education_basic.4y  1.699442e-04\n",
      "43                      month_apr  1.618516e-04\n",
      "52                      month_sep  1.618516e-04\n",
      "46                      month_jul  1.375738e-04\n",
      "56                day_of_week_tue  9.711095e-05\n",
      "15                   job_services  5.664805e-05\n",
      "47                      month_jun  4.046290e-05\n",
      "53                day_of_week_fri  3.237032e-05\n",
      "39                   loan_unknown  2.427774e-05\n",
      "17                 job_technician  2.427774e-05\n",
      "36                housing_unknown  2.427774e-05\n",
      "28           education_illiterate  0.000000e+00\n",
      "34                    default_yes  0.000000e+00\n",
      "23                marital_unknown  0.000000e+00\n",
      "7          was_contacted_before_1  0.000000e+00\n",
      "14              job_self-employed -2.220446e-17\n",
      "26             education_basic.9y -4.440892e-17\n",
      "45                      month_dec -8.092579e-06\n",
      "19                    job_unknown -8.092579e-06\n",
      "30    education_university.degree -2.427774e-05\n",
      "10               job_entrepreneur -3.237032e-05\n",
      "32                     default_no -4.855547e-05\n",
      "18                 job_unemployed -4.855547e-05\n",
      "9                 job_blue-collar -5.664805e-05\n",
      "11                  job_housemaid -5.664805e-05\n",
      "40                       loan_yes -5.664805e-05\n",
      "21                marital_married -6.474063e-05\n",
      "29  education_professional.course -8.901837e-05\n",
      "55                day_of_week_thu -9.711095e-05\n",
      "16                    job_student -9.711095e-05\n",
      "37                    housing_yes -1.132961e-04\n",
      "33                default_unknown -1.294813e-04\n",
      "8                      job_admin. -1.375738e-04\n",
      "25             education_basic.6y -1.375738e-04\n",
      "38                        loan_no -1.375738e-04\n",
      "31              education_unknown -2.104071e-04\n",
      "50                      month_nov -2.346848e-04\n",
      "35                     housing_no -2.427774e-04\n",
      "49                      month_may -2.427774e-04\n",
      "13                    job_retired -2.994254e-04\n",
      "5                       euribor3m -3.398883e-04\n",
      "1                             age -7.202395e-04\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Convert the sparse matrix to a dense array\n",
    "X_test_all_dense = X_test_all_transformed.toarray()\n",
    "\n",
    "# Calculate permutation importance\n",
    "svm_model = best_models['SVM']\n",
    "result = permutation_importance(svm_model, X_test_all_dense, y_test_all, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Create a DataFrame to view the feature importances\n",
    "permutation_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': result.importances_mean\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Permutation Importance for SVM:\")\n",
    "print(permutation_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
